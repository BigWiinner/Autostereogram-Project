# Autostereogram-Project
Live autostereogram generation using a kinect v1 and TouchDesigner

# Use Guide
In order to set this up, you're going to need:
- A version of TouchDesigner installed
- An Xbox Kinect (I used a v1)
- Kinect for Windows SDK (for the Kinect v1, use version [1.8](https://www.microsoft.com/en-us/download/details.aspx?id=40278))
- If the Kinect doesn't have a USB A, then you will also need a Kinect USB 2.0 to USB Type A adapter
- A monitor with no blurring (it will mess up the pattern needed to produce the effect). I also recommend using a monitor or TV screen below a 42" so the image is more easily visible. Most laptop and computer        screens should be fine, but some TV screens try to alter the screen ratio or sharpen the image which can mess up the autostereogram effect.

Download Kinect for Windows SDK and then plug the Kinect into your computer. Then load the project file on TouchDesigner.

# Postmortem
This project was my first foray into TouchDesigner. Originally this project was meant to be in Processing but once I found out TouchDesigner had native support for the Xbox Kinect v1 I swapped over. It was quite the challenge for me to pick up because I have not used a developer environment like TouchDesigner's until now (trying to compare it to something like Unity's shadergraph helped me a lot in better understanding it) and so a lot of my time spent during the course of this project reading the documentation just to figure out how it worked (and a LOT of YouTube tutorials [thanks especially to CutMod and The Interactive & Immersive HQ for your stellar videos which I will link below!]). Overall I became really happy with this project. I'm a big fan of autostereograms and I always wondered why there weren't too many public resources towards making your own, especially live generation, so I hope this project can help at least one other person out there who was like me and also wanted an opportunity to record myself in an autostereogram format :)
I am really happy with how the visual aesthetic of this program, which mostly resulted from a issue I didn't have time to fix so instead tried to work around. Basically if the Kinect is constantly updating the final image with the depth map footage, it becomes possible to see the outine of the person in the noise image without it being the parallax effect. If I had more time I would have found a way to make it so that it could continue to capture footage at about 60FPS and display that completely to the final image, but instead I made it so that it only runs at about 5FPS. This ended up creating a sort of slideshow representation, which reminded me of old fashioned image collections like The Horse in Motion, so I also added a color filter to give it that old video film scheme. It ended up looking really cool in my opinion, like making a flip book version of an autostereogram. Another thing I would have looked into would be a way to record footage of the autostereogram in action without having to use an external software like OBS. But to finish up my thoughts I am really happy with how the project turned out, and hopefully somebody out there who also likes autostereograms will appreciate this too :)

# Artistic Statement
There were two things that made me want to make this program. Firstly when I was in highschool I had an amaznig rhetoric teacher who loved autostereograms (specifically Magic Eye). He would show us books about them and project them on the wall and have competitions to see who could identify the hidden image the fastest. They ended up giving me a long-term appreciation for autostereograms, and it made me want to see if I could add something to the medium.
The other reason is because when I first started to code, I made a personal project to make an autostereogram image in MatLab. The program worked terribly, and all it did was show a basic pixel art image of Pikachu. So I wanted to try again and make something more with the idea I first made a few years ago. I'm happy to see the progress I've made!

# Credits
As mentioned before, there were a lot of guides that helped me in making this project. Here are the links to the videos I used:
[The Interactive & Immersive HQ](https://www.youtube.com/watch?v=Ljx381Wqyo4&t=689s) has a great video talking about using Kinect, and I ended up using their method on converting inverting the depth map color images (for some reason with the Kinect, the depth map shows close object as black where farter objects are white. In depth maps it's normally the other way around). It specifically is talking about how to use this method on the Kinect Azure but I found it to be applicable to the v1 Kinect as well.
[The Interactive & Immersive HQ](https://www.youtube.com/watch?v=p-lhmCMxn2g&t=978s) has an amazing video on manipulating the depth map to wittle out some of the excess object that the Kinect picked up on. This helped make sure it was only considering depth data at a certain range, and not adding things like the floor or ceiling or background object to the autostereogram. 
[CutMod](https://www.youtube.com/watch?v=3M7vNEi0eyM) also has a great couple videos going over the functionality of the Kinect. I especially like the video I linked going over the CHOPs and their funcionality
and their [TOPs](https://www.youtube.com/watch?v=r-EOtQhdJxg&t=247s) video is also really good!
[CutMod](https://www.youtube.com/watch?v=zW7iHrU_f3c) also shows how to track the skeleton in TouchDesigner, which was really helpful in understanding how to go about tracking the hand movements for the start of my program
